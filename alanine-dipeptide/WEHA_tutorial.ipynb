{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5243181d-b805-4ddb-ac9b-27e79caf7cb0",
   "metadata": {},
   "source": [
    "# Conformational sampling of Alanine Dipeptide with weighted ensemble Hamiltonian annealing\n",
    "Authors: Baily Ford<br>\n",
    "Email:&nbsp;&nbsp; bwf15@pitt.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac245ced-b819-4131-b088-4937883f6e3e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa235c0e-6e21-411d-8552-c5ee4ce2fa52",
   "metadata": {},
   "source": [
    "Welcome! This notebook is made with the assumption that you're working on `jupyter.crc.pitt.edu` (or `hub.crc.pitt.edu`) and have setup your virtual environments using https://github.com/Bailyford/drug-design2025_weha. If not, follow the steps in \"[Setting up the virtual environment](#Setting-up-the-virtual-environment)\".\n",
    "\n",
    "To start, make sure it says `drug-design2025_weha` on the top right hand corner! If it doesn't, click on `Python 3 (ipykernel)` (Or whatever it currently is) and select `drug-design2025_weha` from the drop down menu as your preferred kernel. Click Select.\n",
    "\n",
    "![image](./img/Notebook-kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037a09d-7e0d-4323-83c0-b673638a9853",
   "metadata": {},
   "source": [
    "### Setting up the virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7278c7d-292d-460d-8839-565dfcc7efad",
   "metadata": {},
   "source": [
    "Follow the instructions in venv_instructions.pdf. Here are the condensed steps:\n",
    "\n",
    "Start a terminal (Should be an option in the \"Launcher\" tab)\n",
    "run python -m pip install nglview\n",
    "Reset the Jupyter Server.\n",
    "run cd ~\n",
    "run git clone https://github.com/Bailyford/drug-design2025_weha\n",
    "run cd drug-design2025_weha\n",
    "run bash run_bash.sh then wait. It might take a short while.\n",
    "run bash activate_env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7afb491-8c81-4c4f-8d41-b4f8b0117cf4",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- modify an AMBER parameter file to change force field calculations\n",
    "- generate starting structures\n",
    "- prepare simulation files for conformational sampling with WEHA of Alanine Dipeptide\n",
    "- submit a slurm job to the pitt crc cluster\n",
    "- clustering conformations with Kmeans NANI\n",
    "- use <code>WEDAP</code> to generate Ramanchandra plots of  \n",
    "- Visualize the results of clustering with <code>matplotlib</code>\n",
    "- calculate state populations using structure weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773480b-55de-4f07-8483-8eb4ff01a315",
   "metadata": {},
   "source": [
    "System Requirements\n",
    "AmberTools24 is necessary to run this simulation.\n",
    "Note that it is already installed as a module on H2P\n",
    "numpy, matplotlib, ipympyl, mdtraj, and nglview are used in this jupyter notebook.\n",
    "nglview, matplotlib, ipympl, and numpy are optional for visualization purposes.\n",
    "These are already installed as part of the virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793d3eb-1efa-4bcd-b6c2-b7f94c7225af",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7893a7-9a6a-4d05-8dc2-4567183f6070",
   "metadata": {},
   "source": [
    "[Introduction](#Introduction)\n",
    "\n",
    "Day 1:\n",
    "\n",
    "[1. Scaling the Hamiltonian and generating initial states](#1.-Scaling-the-Hamiltonian-and-generating-initial-states)\n",
    "\n",
    "[2. Prepare WEHA input files](#2.-Prepare-WEHA-input-files)\n",
    "\n",
    "[3. Running WEHA Simulation](#3.-Run-WEHA-Simulation)\n",
    "\n",
    "Day 2:\n",
    "[4. Visualize the Results](#4.-Visualize-the-results)\n",
    "\n",
    "[5. Analyze the MD Results](#5.-Analyze-the-MD-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77b7c0-2fe3-4755-8d92-0abf23f810d5",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401498c-53dd-4c46-bad1-b8b34b0eed31",
   "metadata": {},
   "source": [
    "This tutorial is designed to provide an introduction to conformational sampling of biomolecules with the weighted ensemble Hamiltonian Annealing (WEHA) method of the WESTPA software package. It is designed for alanine dipeptide in AMBER 24. This notebook is designed with the assumption that you are working within a virtual environment on the H2P Cluster at Pitt.\n",
    "\n",
    "AMBER stands for Assisted Model Building and Energy Refinement. It refers not only to the molecular dynamics programs, but also a set of force fields that describe the potential energy function and parameters of the interactions of biomolecules.\n",
    "\n",
    "In order to run a Molecular Dynamics simulation in Amber, each molecule's interactions are described by a molecular force field. WEHA aims to yield Boltzmann-weighted ensembles by reducing the energy barrier between conformations induced by torsional and non-bonded interactions. This scaling is gradually reduced with frequent resampling in which trajectories with large weights are duplicated and trajectories with small weights are terminated.\n",
    "We will be using Amber's gpu accelerated <code>pmemd.cuda</code> to handle all dynamics propogation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f219ae-bf89-4332-9abd-84c8eefb474c",
   "metadata": {},
   "source": [
    "## 1. Scaling the Hamiltonian and generating initial states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc2364-4883-4ecd-95a1-b83148fafb68",
   "metadata": {},
   "source": [
    "The first step to creating your basis (starting) states is to properly scale the Hamiltonian. This is done by introducing an alchemical scaling factor, λ, to the torsional and non-bonded terms. We have to be careful with our scaling, however, as irresponsible scaling can result in the solvent box evaporating. As such, we should avoid scaling any non-bonded interactions that willl aid in conformational sampling. In this case, only solute-solute and solute-solvent interactions are scaled. Thus, we need to figure out how each Lennard-Jones interaction is calculation. Put simply, atoms with similar van der Waal radii and well depth are grouped together and assigned a numeric type index. In the prmtop file, the are values for interactions between each type index. In this case, we want to scale everything except for water-water interactions. We can figure out which index values correspond to each atom group using PARMED as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b94ec-a59e-4a25-b6d6-959342e996e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parmed\n",
    "from parmed.tools import printLJTypes\n",
    "from parmed.amber import AmberParm\n",
    "parm = AmberParm('common_files/diala.prmtop')\n",
    "action = printLJTypes(parm)\n",
    "action.execute()\n",
    "print('%s' % action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2704db2-aaaa-4c46-8fb9-6f67147d9c5b",
   "metadata": {},
   "source": [
    "We can modify the proper terms using the python script `modprmtop.py` that is located within the `common_files/` subdirectory. `Modprmtop.py` takes 4-6 arguments based on the flage chosen. For all flags, the arguments are as follows: the value of λ, the prmtop file flag to modify, the prmtop file being modified, and the new prmtop file in that order. If the flag is `CHARGE`, an addition argument is needed for the number of atoms we wish to scale. In this case, this is all non-water charges. If the flag is a `lennard_jones` parameter, a 5th and 6th parameter are needed that specify the last soulte LJ type (5) and the last solvent LJ type (6). In the code below are some dummy arguments (X) for the additional arguments. Using the results you found from `parmed`, fill in these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f1204-af1d-465c-82c7-19d54b6a69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python common_files/modprmtop.py 0.2 CHARGE common_files/diala.prmtop common_files/mod.prmtop X #Modify X here\n",
    "!python common_files/modprmtop.py 0.2 DIHEDRAL_FORCE_CONSTANT common_files/mod.prmtop common_files/mod.prmtop\n",
    "!python common_files/modprmtop.py 0.2 LENNARD_JONES_ACOEF common_files/mod.prmtop common_files/mod.prmtop X X #and here\n",
    "!python common_files/modprmtop.py 0.2 LENNARD_JONES_BCOEF common_files/mod.prmtop common_files/mod.prmtop X X #here too\n",
    "\n",
    "!diff common_files/diala.prmtop common_files/mod.prmtop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f6335-88a7-4b44-b2a9-cebba63b3e3d",
   "metadata": {},
   "source": [
    "To generate suitable initial states, we need to create an ensemble of scaled down structures. The simplest way to do this is to gradually reduce the torsional and non-bonded interactions in our system with sufficient equilibration. This is analogous to equilibrating a system at constant pressure in whihc you are gradually removing restraints. A subsequent, brief conventional md simulation is then ran with frames frequently saved that will serve as the starting structures. Because alanine dipeptide is a small molecule, we should not need to impose any restraints. To save time, an equilibrated, reduced hamiltonian, restart file has been provided in 'common_files/initial.ncrst.' An example of the code used to generate this state is shown below, but **note that it does not need to be executed for the purposes of this tutorial**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3d18a-cfd0-4286-a7a4-d2dff857e130",
   "metadata": {},
   "source": [
    "```\n",
    "#Example code Do not run!\n",
    "\n",
    "for x in $(seq 0.95 -0.05 0.20 | awk '{printf \"%.2f\\n\", $1}'); do\n",
    "    python modprmtop.py $x CHARGE diala.prmtop mod.prmtop 22 &&\\\n",
    "    python modprmtop.py $x DIHEDRAL_FORCE_CONSTANT mod.prmtop mod.prmtop &&\\\n",
    "    python modprmtop.py $x LENNARD_JONES_ACOEF mod.prmtop mod.prmtop 7 10 &&\\\n",
    "    python modprmtop.py $x LENNARD_JONES_BCOEF mod.prmtop mod.prmtop 7 10 &&\\\n",
    "\n",
    "    if [[ \"$x\" == \"0.95\" ]]; then\n",
    "        prev_x=\"1\"\n",
    "    else\n",
    "        prev_x=$(printf \"%.2f\" $(echo \"$x + 0.05\" | bc -l))\n",
    "    fi\n",
    "\n",
    "    pmemd.cuda -O -i lambda_equil.in -o lambda_${x}.out -p mod.prmtop \\\n",
    "        -c ${prev_x}.ncrst -r ${x}.ncrst -x ${x}.nc -inf ${x}.info -AllowSmallBox\n",
    "done\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b87d5a2-d24e-4a78-af60-890a0ac7d596",
   "metadata": {},
   "source": [
    "### Generating Starting Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90b8e1-16e6-4670-940b-c59df7d1ab0b",
   "metadata": {},
   "source": [
    "Now that we have a scaled starting structure, we can use this structure to generate the rest. We will do so by starting a brief conventional, scaled, md run from initial.ncrst in the common_files subdirectory using pmemd. We will save the trajectory and write a new restart file every 2 ps. The Langevin thermostat will be used to control the temperature. The random number generator will be initialized with a random seed.\n",
    "\n",
    "To control all these settings, we will write a simple input file in a text editor. Unix has many text editors available, but we will use the one built into Jupyter Lab.\n",
    "\n",
    "The following cell will create the file. You may open (and edit) the file by double clicking it in the file browser to the left. Edit it to your liking (and press Cmd/Ctrl+s to save). You may edit the rate that restart files are saved to adjust the number of starting states to your liking. Try picking a value that you believe will both best represent a Boltzmann distribution (many entries) while keeping the simulation time managable. Amber will write a new file every ntwr steps. **The final count is equal to nstlim/ntwr. Your final count should fall between 50-200 starting states. Be sure that ntwr is a negative value.** This lets Amber know to save a new file rather than overwrite a previous file. The output files will be enumerated by the frame they were written on and can be rewritten later. To keep time manageable, only change the value of ntwr. A set of starting structures are provided in the supplemental_data subdirectory if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd2ea2e-b120-474b-910e-cca978c2808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing common_files/get_bstates.in\n"
     ]
    }
   ],
   "source": [
    "%%writefile common_files/get_bstates.in\n",
    "1 ns unrestrained NPT equilibration using Langevin thermostat and MC barostat\n",
    " &cntrl\n",
    "  irest     = 1,\n",
    "  ntx       = 5,\n",
    "  ig        = -1,\n",
    "  dt        = 0.002,\n",
    "  nstlim    = 500000,\n",
    "  nscm      = 500,\n",
    "  ntr       = 0,\n",
    "  ntb       = 2,\n",
    "  ntp       = 1,\n",
    "  barostat  = 2,\n",
    "  pres0     = 1.0,\n",
    "  mcbarint  = 100,\n",
    "  comp      = 44.6,\n",
    "  taup      = 1.0,\n",
    "  ntt       = 3,\n",
    "  temp0     = 300.0,\n",
    "  gamma_ln  = 1.0,\n",
    "  ntf       = 2,\n",
    "  ntc       = 2,\n",
    "  cut       = 10.0,\n",
    "  ntpr      = 1000,\n",
    "  ntxo      = 2,\n",
    "  ntwr      = -5000, ! Replace x with a value that satisfies the above conditions\n",
    "  ioutfm    = 1,\n",
    "  ntwx      = 10000,\n",
    "  iwrap     = 1,\n",
    " /\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18da442-9c6d-4d9a-8985-a698ed345cb6",
   "metadata": {},
   "source": [
    "In a new terminal, execute the following commands to generate the basis states. This will take approximately 30 minutes. You may skip to section 2 in the mean time. [2. Prepare WEHA input files](#2.-Prepare-WEHA-input-files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f1d02-097a-4a7c-af6f-1f966e8102ec",
   "metadata": {},
   "source": [
    "```\n",
    "module load gcc/10.2.0 openmpi/4.1.1 amber/24 &&\\\n",
    "pmemd.cuda -O -i common_files/get_bstates.in -o bstates.out -p common_files/mod.prmtop -c common_files/initial.ncrst -x production.nc -inf base.info -AllowSmallBox\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07cecc-7017-4000-acf6-1051ced9c956",
   "metadata": {},
   "source": [
    "### Assigning Initial Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea5e1d-41cd-46c6-9436-5a658547f95e",
   "metadata": {},
   "source": [
    "Now that you have generated an ensemble of structures to start with, it is time to assign each structure a weight proportional to its Boltzmann factor. In statistical mechanics and mathematics, a Boltzmann distribution is a probability distribution or probability measure that gives the probability that a system will be in a certain state as a function of that state's energy and the temperature of the system. The distribution is expressed in the form:\n",
    "$$p_i ∝ exp(\\frac{\\epsilon_{i}}{kT})$$\n",
    "\n",
    "where $p_i$ is the probability of the system being in state i, exp is the exponential function, $ε_i$ is the energy of that state, and a constant kT of the distribution is the product of the Boltzmann constant k and thermodynamic temperature T. In our case, the system is the ensemble of alanine dipeptide states. Any state that is more stable (lower energy) will have a higher probability of occuring. Because our solute is small and the number of water molecules and system temperature are constant, we can assume that any differences in energy between our systems from the solvent is negligible. Because the Boltzmann distribution is an absolute relationship between energy and probability, we are able to standardize our energies so that we are concerned with the differences in potential energy between states.\n",
    "\n",
    "We can get this energy by using the CPPTRAJ toolkit, a software package for analyzing AMBER simulations. **For the following 3 files, replace $B with the total number of generated bstates. For the .py files, remember to add 1 to that value. I.E if 100 states, range is (1, 101).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61dcba-ab38-4251-a456-a54291c81f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load gcc/10.2.0 openmpi/4.1.1 amber/24\n",
    "N=$B #Set x to the chosen number of starting states. \n",
    "counter=1\n",
    "for file in restrt*; do\n",
    "    new_name=$(printf \"%02d\" $counter)\n",
    "#rename the file\n",
    "    mv \"$file\" \"bstates/${new_name}.ncrst\"\n",
    "    counter=$((counter + 1));\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2c0fba-0090-412f-bf9d-1583d5a59c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: module: command not found\n",
      "bash: line 5: printf: 1.ncrst: invalid number\n",
      "mv: cannot stat 'restrt*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "module load gcc/10.2.0 openmpi/4.1.1 amber/24\n",
    "N=$B #Set x to the chosen number of starting states. \n",
    "for i in $(seq 1 $N); do\n",
    "    x=$(printf \"%02d\" $i)\n",
    "    cpptraj $top << EOF > /dev/null\n",
    "parm common_files/mod.prmtop\n",
    "trajin bstates/$x.ncrst\n",
    "autoimage\n",
    "strip :WAT\n",
    "energy @1-22 out energy_$x.dat\n",
    "go\n",
    "EOF\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4dd4a1-8873-48f2-9d2d-a5b9750186fe",
   "metadata": {},
   "source": [
    "While WEHA lacks the traditional progress coordinate that weighted ensemble uses, Westpa requires that we have a progress coordinate that defines how our system progresses. In this case we will use the dihedral angle phi. This will be explained in more detail later, but for now we need to create two files: pcoord.init and bstates.txt. pcoord.init will contain the initial phi angle and energy for each state. bstates.txt will contain the starting weight and location of each state. First, lets make pcoord.init by using MDtraj to calculate the phi angel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8eed9-b151-46db-89e2-c71b95b212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import mdtraj\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "N = $B #Assign number of starting states here\n",
    "names = []\n",
    "energy = []\n",
    "phi_list = []\n",
    "\n",
    "# Iterate over frames with zero-padded filenames\n",
    "for i in trange(1, N+1, desc='names'):\n",
    "    # Zero-padding file names\n",
    "    names.append(f\"{i:02d}.ncrst\")\n",
    "\n",
    "for i in trange(1, N+1, desc='energy'):\n",
    "    # Read energy file and store energy in the list\n",
    "    energy_data = pd.read_csv(f'energy_{i:02d}.dat', sep=\"\\s+\")\n",
    "    energy.append(energy_data.iloc[0, 9])\n",
    "\n",
    "for i in trange(1, N+1, desc='phi'):\n",
    "    traj = mdtraj.load('bstates/'+str(i).zfill(2)+'.ncrst', top = 'common_files/mod.prmtop')\n",
    "    _, phi = mdtraj.compute_phi(traj)\n",
    "    phi = np.squeeze(phi) *180/np.pi\n",
    "    phi_list.append(phi)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'file': names, 'phi': phi_list, 'energy': energy})\n",
    "\n",
    "df['energy'] = df['energy']-df['energy'].min()\n",
    "# Save DataFrame to a file without brackets around RMSD values\n",
    "df.to_csv('bstates/pcoord.init', sep='\\t', index=False, header=True, float_format='%.6f')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632388d-398a-4de7-86f5-9849e8f11539",
   "metadata": {},
   "source": [
    "And now the bstates.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18678328-1d41-4c1c-ad18-1a0f2d618bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "N = $B\n",
    "\n",
    "df = pd.read_csv('bstates/pcoord.init', delim_whitespace=True)\n",
    "prenormalized_weight = []\n",
    "weight = []\n",
    "\n",
    "for i in range(0, N): #This $B is an exception to the +1 rule. This should be the number of starting states.\n",
    "    x = np.exp((float(df.iloc[i, 2])/(-0.002*300)))\n",
    "    prenormalized_weight.append(x)\n",
    "print(prenormalized_weight)\n",
    "\n",
    "partition = sum(prenormalized_weight)\n",
    "for x in prenormalized_weight:\n",
    "    final_weights = x/partition\n",
    "    weight.append(final_weights)\n",
    "\n",
    "bstate = []\n",
    "for x in range(1, N+1):\n",
    "    bstate.append(f\"{x:02d}\")\n",
    "\n",
    "rd = []\n",
    "for y in range(1, N+1):\n",
    "    rd.append(f\"{y:02d}\")\n",
    "df2 = pd.DataFrame({'file': bstate, 'weight': weight, 'rd': rd})\n",
    "df2.to_csv('bstates/bstates.txt', sep='\\t', index=False, header=False)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b59ea0-4d7c-4ba9-8739-65c2abb66ce1",
   "metadata": {},
   "source": [
    "Clean up the working directory by removing the unneed `energy.dat` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76388091-3a17-4354-8352-8b882f6cb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm energy_*.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b89a27-e1a8-40e1-991c-f374bf081c15",
   "metadata": {},
   "source": [
    "## 2. Prepare WEHA input files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38346558-6ff1-4f93-a7f8-a711b5434e39",
   "metadata": {},
   "source": [
    "As a subset of the WESTPA software package, there are a few additional files that are required to configure, propogate, and resample our trajectories. Most of these files are consistent between weighted ensemble simulations and will be ignored for the purposes of this tutorial. The files that are required that we will look at are the westpa configuration file, `west.cfg`, the custom WEHA resampler, `resampler.py`, the AMBER dynamics production file, `production.in`, calculation of the dihedral angles phi and psi with `get_dihedrals.py`, and the script `runseg.sh` that controls the iterative processes of WESTPA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5bcad-9f96-4dbf-b843-a317865d6839",
   "metadata": {},
   "source": [
    "### West.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a0516-2510-4cb0-a41e-cd618a47156a",
   "metadata": {},
   "source": [
    "This is the configuration file that controls the parameters of the WEHA simulation. There are three main sections to focus on: drivers, system, and data. The drivers section destermines both the root directory for the simulation as well as which algorithm we will be using to handle our resampling. As we are using a custom resampler, this value should be set to resampler.CustomDriver.\n",
    "\n",
    "The system section handles the dimensionality of the data, the size of the dataset, its data type, and specifies how we wish to define our binning. As WEHA is efefctively a binless, progress coordinate-less approach to weighted ensemble, we should define our bins so that our entire progress coordinate falls within a singular bin. Becasue our progress coordinate is the one-dimensional dihedral angle 'phi', our bin will have the shape [-180, 180]. If desired, [0, 360] is also acceptable if that notion is kept consistent elsewhere.\n",
    "\n",
    "The most important section is data. Here we have to define all datasets that will be used in the simulation. For WEHA we need to store the to dihedral angles 'phi' and 'psi' as well as the total energy, each on the constituent energies (angle, bond, dihedral, van der Waals, and electrostatics), and the three-dimensional coordinates of each structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba713ed-4b58-4152-ad0e-8a8f21a8f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile west.cfg\n",
    "# The master WEST configuration file for a simulation.\n",
    "# vi: set filetype=yaml :\n",
    "---\n",
    "west: \n",
    "  drivers:\n",
    "    module_path: $WEST_SIM_ROOT\n",
    "    we_driver: resampler.CustomDriver\n",
    "  system:\n",
    "    driver: westpa.core.systems.WESTSystem\n",
    "    system_options:\n",
    "      # Dimensionality of your progress coordinate\n",
    "      pcoord_ndim: 1\n",
    "      # Number of data points per iteration\n",
    "      pcoord_len: 10\n",
    "      # Data type for your progress coordinate \n",
    "      pcoord_dtype: !!python/name:numpy.float32\n",
    "      # begin fixed binning\n",
    "      bins:\n",
    "        type: RectilinearBinMapper\n",
    "#        # The edges of the bins \n",
    "        boundaries:         \n",
    "          -  [-180, 180]\n",
    "      bin_target_counts: 100\n",
    "  propagation:\n",
    "    max_total_iterations: 10000\n",
    "    max_run_wallclock:    48:00:00\n",
    "    propagator:           executable\n",
    "    gen_istates:          false\n",
    "  data:\n",
    "    west_data_file: west.h5\n",
    "    datasets:\n",
    "       - name:        pcoord\n",
    "         scaleoffset: 4\n",
    "       - name: energy\n",
    "         scaleoffset: 4\n",
    "         dtype: float32     \n",
    "       - name: dih_energy\n",
    "         scaleoffest: 4\n",
    "         dtype: float32\n",
    "       - name: vdw_energy\n",
    "         scaleoffest: 4\n",
    "         dtype: float32\n",
    "       - name: elec_energy\n",
    "         scaleoffest: 4\n",
    "       - name: bond_energy\n",
    "         scaleoffset: 4\n",
    "         dtype: float32\n",
    "       - name: angle_energy\n",
    "         scaleoffset: 4\n",
    "         dtype: float32\n",
    "       - name: coordinates\n",
    "         scaleoffset: 4\n",
    "         dtype: float32\n",
    "       - name: psi\n",
    "         scaleoffset: 4\n",
    "         dtype: float32\n",
    "    data_refs:\n",
    "#      iteration:     $WEST_SIM_ROOT/traj_segs/iter_{n_iter:06d}.h5\n",
    "      segment:       $WEST_SIM_ROOT/traj_segs/{segment.n_iter:06d}/{segment.seg_id:06d}\n",
    "      basis_state:   $WEST_SIM_ROOT/bstates/{basis_state.auxref}\n",
    "      initial_state: $WEST_SIM_ROOT/istates/{initial_state.iter_created}/{initial_state.state_id}.ncrst\n",
    "  plugins:\n",
    "  executable:\n",
    "    environ:\n",
    "      PROPAGATION_DEBUG: 1\n",
    "    datasets:\n",
    "      - name: energy\n",
    "        enabled: true\n",
    "      - name: dih_energy\n",
    "        enabled: true\n",
    "      - name: vdw_energy\n",
    "        enabled: true\n",
    "      - name: elec_energy\n",
    "        enabled: true\n",
    "      - name : bond_energy\n",
    "        enabled: true\n",
    "      - name: angle_energy\n",
    "        enabled: true\n",
    "      - name: coordinates\n",
    "        loader: npy_loader\n",
    "        enabled: true\n",
    "        filename: $WEST_SIM_ROOT/traj_segs/{segment.n_iter:06d}/{segment.seg_id:06d}/coordinates.npy\n",
    "        dir: true\n",
    "      - name: psi\n",
    "        enabled: true\n",
    "    propagator:\n",
    "      executable: $WEST_SIM_ROOT/westpa_scripts/runseg.sh\n",
    "      stdout:     $WEST_SIM_ROOT/seg_logs/{segment.n_iter:06d}-{segment.seg_id:06d}.log\n",
    "      stderr:     stdout\n",
    "      stdin:      null\n",
    "      cwd:        null\n",
    "      environ:\n",
    "        SEG_DEBUG: 1\n",
    "    get_pcoord:\n",
    "      executable: $WEST_SIM_ROOT/westpa_scripts/get_pcoord.sh\n",
    "      stdout:     /dev/null #$WEST_SIM_ROOT/get_pcoord.log\n",
    "      stderr:     stdout\n",
    "    gen_istate:\n",
    "      executable: $WEST_SIM_ROOT/westpa_scripts/gen_istate.sh\n",
    "      stdout:     /dev/null \n",
    "      stderr:     stdout\n",
    "    post_iteration:\n",
    "      enabled:    true\n",
    "      executable: $WEST_SIM_ROOT/westpa_scripts/post_iter.sh\n",
    "      stderr:     stdout\n",
    "    pre_iteration:\n",
    "      enabled:    false\n",
    "      executable: $WEST_SIM_ROOT/westpa_scripts/pre_iter.sh\n",
    "      stderr:     stdout\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e2878-5b8e-485d-8669-ada9cfc15235",
   "metadata": {},
   "source": [
    "### Resampler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ca55e-71a2-445b-815b-319a0e1e93ff",
   "metadata": {},
   "source": [
    "This files is responsible for handling the custom resampling and is the most important file for the WEHA method. This files is quite large so we will not be analyzing it in depth, but it is important to note that this file handles an adaptive annealing schedule, reweighting segments, and splitting/mergeing trajectories. **In jupyterhub, open resampler.py. On lines 22-25, change the variables so that they match the number of starting states, initial lambda value, and the desired effective sample size.**\n",
    "The effective sample size is a measure of how correlated your data is. The larger the value, the less autocorrelation. We calculate this with Kish's approximation: \n",
    "\n",
    "$$ ESS = (\\sum^{N}_{i=1}{p_i})^2/(\\sum^{N}_{i=1}{p_i^2})$$ \n",
    "where $p_i$ is the probability of state i and N is the total number of trajectories. The closer the trajectories weights are, the closer the ESS approaches N. Functionally, this controls the rate of annealing and is a generalized cost vs rewards function. A large ESS promotes a slower annealing with multiple iterations with smaller λ increments. Note that a larger ESS leads to better convergence and consistency, but is ultimately subjected to diminishing returns. An ESS of 99 vs 98 is only marginally more consistent yet takes about 2 additional hours to run. Try picking an effective sample size that you believe will work best for the chosen number of starting states. Do note that ESS must be less than N."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40fc4e-6bac-4c44-8329-beffe3f62bd1",
   "metadata": {},
   "source": [
    "### Production.in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bbae8-1479-45d6-a4dd-4e04bda079b2",
   "metadata": {},
   "source": [
    "This is AMBER input script that handles all propogation. We should establish constant temperature and pressure, NPT, with the Monte Carlo barostat and Langevin thermostat. This script runs for 100 ps and saves information every 10 ps. Be sure that `ig=RAND` is set as this indicates to WESTPA to use its own random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f6839-2cf5-43df-a65b-47d35d4f41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile common_files/production.in\n",
    "Production file\n",
    "&cntrl\n",
    " imin=0,\n",
    " irest=1,\n",
    " ntx=5,\n",
    " ntpr=5000,\n",
    " ntwx=5000,\n",
    " ntwr=5000,\n",
    " nstlim=50000,\n",
    " dt=0.002,\n",
    " ntt=3,\n",
    " tempi=300,\n",
    " temp0=300,\n",
    " gamma_ln=1.0,\n",
    " ig=RAND,\n",
    " ntp=1,\n",
    " ntc=2,\n",
    " ntf=2,\n",
    " cut=9,\n",
    " ntb=2,\n",
    " iwrap=1,\n",
    " ioutfm=1,\n",
    " barostat=2,\n",
    " pres0=1.0,\n",
    " mcbarint=100,\n",
    " comp=44.6,\n",
    " taup=1.0\n",
    "&end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd25a57-61ae-437d-9268-81fde7b8c8b8",
   "metadata": {},
   "source": [
    "### Get_Dihedrals.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20498e24-6f3a-4098-a2c4-5b29a0453042",
   "metadata": {},
   "source": [
    "This script will use MDTraj to compute the dihedral angles of each structure at the ened of each propogation. This file should save angles for each saved frame for both 'phi' and 'psi' in an easily differentiable way. This can either be done as two seperate files as shown below, or as a singular file with 2 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaeacd3-7476-41b6-90c3-8457c24124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile common_files/get_dihedrals.py\n",
    "import numpy as np\n",
    "import mdtraj\n",
    "phi_list = []\n",
    "psi_list = []\n",
    "traj = mdtraj.load('seg.nc', top = 'mod.prmtop')\n",
    "_, phi = mdtraj.compute_phi(traj)\n",
    "_, psi = mdtraj.compute_psi(traj)\n",
    "phi = np.squeeze(phi) *180/np.pi\n",
    "psi = np.squeeze(psi)*180/np.pi\n",
    "np.savetxt('phi.dat', phi)\n",
    "np.savetxt('psi.dat', psi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe148e64-5bcd-4bf2-8b34-3c31665c7704",
   "metadata": {},
   "source": [
    "### Runseg.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9226a-b0bd-4d5d-8c8f-db19a83a9135",
   "metadata": {},
   "source": [
    "This file is located in the westpa_scripts subdirectory and specifies what happens over the course of an iteration. We first want to create a modified prmtop file to use for the upcoming propogation, so we execute those commands first. We then replace RAND in the AMBER submission script with a seed generated from WESTPA's internal RNG. We then run AMBER. Afterwards, we compute all the relevant data and send that data to the corresponding datasets defined in the west.cfg file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ad595-03fe-4b14-932c-a2db836758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile westpa_scripts/runseg.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "if [ -n \"$SEG_DEBUG\" ] ; then\n",
    "  set -x\n",
    "  env | sort\n",
    "fi\n",
    "\n",
    "cd $WEST_SIM_ROOT\n",
    "mkdir -pv $WEST_CURRENT_SEG_DATA_REF\n",
    "cd $WEST_CURRENT_SEG_DATA_REF\n",
    "tempF=$(tail -n 1 $WEST_SIM_ROOT/common_files/lambda.dat | awk '{print $2}')\n",
    "python $WEST_SIM_ROOT/common_files/modprmtop.py $tempF CHARGE $WEST_SIM_ROOT/common_files/diala.prmtop ./mod.prmtop 22\n",
    "python $WEST_SIM_ROOT/common_files/modprmtop.py $tempF DIHEDRAL_FORCE_CONSTANT ./mod.prmtop ./mod.prmtop\n",
    "python $WEST_SIM_ROOT/common_files/modprmtop.py $tempF LENNARD_JONES_ACOEF ./mod.prmtop ./mod.prmtop 7 10\n",
    "python $WEST_SIM_ROOT/common_files/modprmtop.py $tempF LENNARD_JONES_BCOEF ./mod.prmtop ./mod.prmtop 7 10\n",
    " \n",
    "\n",
    "\n",
    "ln -sv $WEST_SIM_ROOT/common_files/diala.prmtop .\n",
    "ln -sv $WEST_SIM_ROOT/common_files/mod.prmtop .\n",
    "ln -sv $WEST_SIM_ROOT/common_files/diala.pdb .\n",
    "\n",
    "#echo $WEST_PARENT_DATA_REF\n",
    "\n",
    "if [ \"$WEST_CURRENT_SEG_INITPOINT_TYPE\" = \"SEG_INITPOINT_CONTINUES\" ]; then\n",
    "  sed \"s/RAND/$WEST_RAND16/g\" $WEST_SIM_ROOT/common_files/production.in > production.in\n",
    "  ln -sv $WEST_PARENT_DATA_REF/seg.ncrst ./parent.ncrst\n",
    "elif [ \"$WEST_CURRENT_SEG_INITPOINT_TYPE\" = \"SEG_INITPOINT_NEWTRAJ\" ]; then\n",
    "  sed \"s/RAND/$WEST_RAND16/g\" $WEST_SIM_ROOT/common_files/production.in > production.in\n",
    "  cp $WEST_PARENT_DATA_REF.ncrst ./parent.ncrst\n",
    "fi\n",
    "\n",
    "export CUDA_DEVICES=(`echo $CUDA_VISIBLE_DEVICES_ALLOCATED | tr , ' '`)\n",
    "export CUDA_VISIBLE_DEVICES=${CUDA_DEVICES[$WM_PROCESS_INDEX]}\n",
    "\n",
    "echo \"RUNSEG.SH: CUDA_VISIBLE_DEVICES_ALLOCATED = \" $CUDA_VISIBLE_DEVICES_ALLOCATED\n",
    "echo \"RUNSEG.SH: WM_PROCESS_INDEX = \" $WM_PROCESS_INDEX\n",
    "echo \"RUNSEG.SH: CUDA_VISIBLE_DEVICES = \" $CUDA_VISIBLE_DEVICES\n",
    "\n",
    "\n",
    "\n",
    "echo $tempF $WEST_SIM_ROOT\n",
    "\n",
    "$PMEMD  -O -i production.in   -p mod.prmtop -c parent.ncrst \\\n",
    "           -r seg.ncrst -x seg.nc      -o seg.log    -inf seg.nfo -AllowSmallBox\n",
    "\n",
    "#DIST=$(mktemp)\n",
    "COMMAND=\"         parm mod.prmtop\\n\"\n",
    "COMMAND=\"$COMMAND trajin $WEST_CURRENT_SEG_DATA_REF/seg.nc\\n\"\n",
    "COMMAND=\"$COMMAND autoimage \\n\"\n",
    "COMMAND=\"$COMMAND strip :WAT \\n\"\n",
    "COMMAND=\"$COMMAND energy  @1-22  out energy.dat \\n\"\n",
    "COMMAND=\"$COMMAND trajout nowater.nc \\n\"\n",
    "COMMAND=\"$COMMAND go\\n\"\n",
    "\n",
    "python $WEST_SIM_ROOT/common_files/get_dihedrals.py\n",
    "echo -e $COMMAND | $CPPTRAJ\n",
    "cat phi.dat > $WEST_PCOORD_RETURN\n",
    "cat psi.dat > $WEST_PSI_RETURN\n",
    "cat energy.dat | tail -n +2 | awk '{print $4}' > $WEST_DIH_ENERGY_RETURN\n",
    "cat energy.dat | tail -n +2 | awk '{print ($5 + $7)}' > $WEST_VDW_ENERGY_RETURN\n",
    "cat energy.dat | tail -n +2 | awk '{print ($6 + $8)}' > $WEST_ELEC_ENERGY_RETURN\n",
    "cat energy.dat | tail -n +2 | awk '{print $2}' > $WEST_BOND_ENERGY_RETURN\n",
    "cat energy.dat | tail -n +2 | awk '{print $3}' > $WEST_ANGLE_ENERGY_RETURN\n",
    "python $WEST_SIM_ROOT/common_files/get_energy.py > $WEST_ENERGY_RETURN\n",
    "python $WEST_SIM_ROOT/common_files/get_coordinates.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81202a4-dee4-4737-80d9-26851f704cc7",
   "metadata": {},
   "source": [
    "Now that all the files are setup, don't forget to go back and finish section 1: [Assigning-Initial-Weights](#Assigning-Initial-Weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05cd46-986e-445e-a860-b818105119cb",
   "metadata": {},
   "source": [
    "## 3. Running WEHA Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8402c-2d16-4da7-9e4c-8a1ba6633068",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30204af2-4868-4d28-8958-0463cf4f948e",
   "metadata": {},
   "source": [
    "Before running any weighted ensemble simulation, you should initialize the simualtion. This cleanses the directory or any old simulation data and prepares the system for new data. Initialization is performed by executing the command below. If you need to restart your simulation for any reason, it is a good idea to reinitialize before hand. Be warned that any data deleted cannot be recovered, so only initialize if you want a fresh restart and have saved all relevent data. You may ignore the conda error and module errors if executed from the block below instead of from the submission script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1da5f6-0685-4b0b-96b6-45b0c44af5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash init.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266c26b-62d2-4aaf-9a36-282c1a1ac68a",
   "metadata": {},
   "source": [
    "### Running WEHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0b8f2-bd9d-4cb4-bfff-4b30bd8074f8",
   "metadata": {},
   "source": [
    "We are now ready to run the WEHA simulation. We will be using 1 gpu node with 4 cores on pitt-crc. To submit a slurm job, we need a submisison script, environment file, and node configuration files. These have been provided in the base directory. This should take a little under a day to run. You can view the progress of your submission by executing the command squeue -u [your pitt username]-M teach. For example, squeue -u bwf15 -M teach would display any jobs running from the bwf15 account. Ideally you should have data to analyze for the second part of the lab, but if something happens, data will be provided. If you notice some issue, feel free to resubmit the job, or reach out to Baily with the error, and he can help restart the job. To start the simulation, execute the block below. This will submit a job request. For more information on the slurm, please refer to crc user manual: https://crc-pages.pitt.edu/user-manual/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76792f96-973a-430f-90d1-84e3fd349d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sbatch run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae58b35-b0e4-436d-804f-84405d33b423",
   "metadata": {},
   "source": [
    "This is the end of today's lab! We will analyze the simulation on Thursday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126c5c9-0235-426a-a6a8-55717a9df0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
